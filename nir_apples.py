# -*- coding: utf-8 -*-
"""NIR Apples.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gh4-pl0Nzwb2OF6hwNLSAdqe8jlsHkju

## Predicting origin of apples based on spectral data

### About this notebook

- The dataset consists of NIR spectroscopy data of 300 apples
- The apples belong to 3 categories - Fuji apples, Red Star apples and Gala apples
- There are 100 samples of each type 
- The apples come from two provinces - Shaanxi and Shandong - 50 from each (50 * 2 * 3 = 300 samples)
- The intention is to use this data and build a classifier that can identify the source of the apples based on its spectral signature


### Process followed:
- After importing the data we do some initial preprocessing on it
- To adjust for the noise present in the data, we perform Savitzky-Golay smoothing 
- After that, we do Multiplicative Scatter Correction - a normalization technique for spectral data
- Post this, by PCA the best 6 components are picked 
- On this data, we use Support Vector Machines as the classifier of choice
- After training the SVM separately on each apple category, we predict the category for the test data

### Reference for the dataset and procedure:
Li, C., Li, L., Wu, Y., Lu, M., Yang, Y., &; Li, L. (2018). Apple variety identification using near-infrared spectroscopy. Journal of Spectroscopy, 2018, 1â€“7. https://doi.org/10.1155/2018/6935197

###For helping me understand MSC and the implementation too:
https://nirpyresearch.com/two-scatter-correction-techniques-nir-spectroscopy-python/

Import the Libraries
"""

import pandas as pd 
import matplotlib.pyplot as plt
import numpy as np

"""Importing the dataset"""

df = pd.read_excel('apple_NIR_dataset.xlsx')
# print(df.head().to_string())

"""Cleaning up the data"""

# remove first two columns
df = df.drop(df.columns[[0,1]], axis=1) 
print(df.head().to_string())

"""Convert the values of reflectance to absorbance"""

def get_absorbance(reflectance):
  return np.log(1/reflectance)

df = df.apply(get_absorbance)

print(df.head().to_string())

"""Use Savitzy-Golay smoothing with a window size of 5"""

from scipy.signal import savgol_filter

filtered = savgol_filter(df, 5, 3, axis=0)

"""Convert the filtered data back to dataframe

"""

# print(filtered)
filtered_df = pd.DataFrame(filtered[:,:])

"""Plot the original data"""

X = df.values[:,:]
# Readings are between 400 nm to 1021 nm with an interval of about 0.33 nm, which resulted in 1888 observations 
wl = np.arange(400,1023.04,0.33)
 
# Plot the spectra
plt.figure(figsize=(12,15))
with plt.style.context(('ggplot')):
    ax1 = plt.subplot(311)
    plt.plot(wl, X.T)
    plt.title('Original data')

"""Plot the filtered data"""

X = filtered_df.values[:,:]
wl = np.arange(400,1023.04,0.33)
 
# Plot the spectra
plt.figure(figsize=(12,15))
with plt.style.context(('ggplot')):
    ax1 = plt.subplot(311)
    plt.plot(wl, X.T)
    plt.title('Data after applying Savitzky-Golay smoothing')

"""Perform Multiplicative scatter correction"""

def msc(input_data, reference=None):
  # mean centre correction
  for i in range(input_data.shape[0]):
    input_data[i,:] -= input_data[i,:].mean()

  # Get the reference spectrum. If not given, estimate it from the mean    
  if reference is None:    
    # Calculate mean
    ref = np.mean(input_data, axis=0)
  else:
    ref = reference

  # Define a new array and populate it with the corrected data    
  data_msc = np.zeros_like(input_data)
  for i in range(input_data.shape[0]):
    # Run regression
    fit = np.polyfit(ref, input_data[i,:], 1, full=True)
    # Apply correction
    data_msc[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] 

  return (data_msc, ref)

"""Plot data after MSC"""

Xmsc = msc(X)[0] # Take the first element of the output tuple

plt.figure(figsize=(12,15))
with plt.style.context(('ggplot')):
  ax2 = plt.subplot(312)
  plt.plot(wl, Xmsc.T)
  plt.ylabel('Absorbance spectra')
  plt.title('MSC')

"""Perform PCA - 2 dimensions for the first apple category - Fuji Apples (samples 0-100)"""

# do PCA separately for each apple category

from sklearn.preprocessing import StandardScaler
# Separating out the features
x = Xmsc[:100,:]
# Standardizing the features
# x = StandardScaler().fit_transform(x)
pre_pca_data = x

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])

x = principalDf['PC1']
y = principalDf['PC2']

plt.xlabel('PC 1')
plt.ylabel('PC 2')
plt.scatter(x[:50],y[:50])
plt.scatter(x[50:],y[50:])

"""PCA - 3 Dimensions"""

from mpl_toolkits.mplot3d import Axes3D

pca3d = PCA(n_components=3)
principalComponents = pca3d.fit_transform(pre_pca_data)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['PC1', 'PC2', 'PC3'])

# same but with 3 principal components

fig = plt.figure()
ax = Axes3D(fig)

sequence_containing_x_vals = principalDf['PC1']
sequence_containing_y_vals = principalDf['PC2']
sequence_containing_z_vals = principalDf['PC3']


ax.set_xlabel('PC 1')
ax.set_ylabel('PC 2')
ax.set_zlabel('PC 3')
ax.scatter(sequence_containing_x_vals[:50], sequence_containing_y_vals[:50], sequence_containing_z_vals[:50])
ax.scatter(sequence_containing_x_vals[50:], sequence_containing_y_vals[50:], sequence_containing_z_vals[50:])
plt.show()

"""Doing PCA on 6 dimensions - to use SVMs"""

pca6d = PCA(n_components=6)
principalComponents = pca6d.fit_transform(pre_pca_data)
principalDf = pd.DataFrame(data = principalComponents)

pd.DataFrame(data = principalComponents)

# Use kernel SVM here
from sklearn.model_selection import train_test_split
X = principalDf
# predictions - first 50 are type A apples (0) and second 50 are type B (1)
z = [0] * 100
z[50:] = [1] * 50
X_train, X_test, y_train, y_test = train_test_split(X, z, test_size = 0.25)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf')
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

print(y_pred)
print(np.array(y_test))
# all predictions match
# 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1
# 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1

"""Predicting for the second category - Red Star apples (samples 100-200)"""

x = Xmsc[100:200,:]
# x = StandardScaler().fit_transform(x)
pre_pca_data = x

# Doing PCA on 6 dimensions

pca6d = PCA(n_components=6)
principalComponents = pca6d.fit_transform(pre_pca_data)
principalDf = pd.DataFrame(data = principalComponents)

# Use kernel SVM here
X = principalDf
# predictions - first 50 are type A apples and second 50 are type B
z = [0] * 100
z[50:] = [1] * 50

X_train, X_test, y_train, y_test = train_test_split(X, z, test_size = 0.25)

sc = StandardScaler()
# SCALING DONE TWICE - REMOVE ONE
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf')
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print(y_pred)
print(np.array(y_test))

# to check how many predictions match
# np.logical_xor(y_pred, np.array(y_test))

"""Predicting for the third category - Gala Apples (samples 200-300)"""

x = Xmsc[200:300,:]
# x = StandardScaler().fit_transform(x)
pre_pca_data = x

# Doing PCA on 6 dimensions

pca6d = PCA(n_components=6)
principalComponents = pca6d.fit_transform(pre_pca_data)
principalDf = pd.DataFrame(data = principalComponents)

# Use kernel SVM here
X = principalDf
# predictions - first 50 are type A apples and second 50 are type B
z = [0] * 100
z[50:] = [1] * 50

X_train, X_test, y_train, y_test = train_test_split(X, z, test_size = 0.25)

sc = StandardScaler()
# SCALING DONE TWICE - REMOVE ONE
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.svm import SVC

classifier = SVC(kernel = 'rbf')
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print(y_pred)
print(np.array(y_test))

